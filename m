Return-Path: <linux-acpi+bounces-2496-lists+linux-acpi=lfdr.de@vger.kernel.org>
X-Original-To: lists+linux-acpi@lfdr.de
Delivered-To: lists+linux-acpi@lfdr.de
Received: from sv.mirrors.kernel.org (sv.mirrors.kernel.org [IPv6:2604:1380:45e3:2400::1])
	by mail.lfdr.de (Postfix) with ESMTPS id AAD5F816447
	for <lists+linux-acpi@lfdr.de>; Mon, 18 Dec 2023 03:15:59 +0100 (CET)
Received: from smtp.subspace.kernel.org (wormhole.subspace.kernel.org [52.25.139.140])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by sv.mirrors.kernel.org (Postfix) with ESMTPS id 5CFC22825E7
	for <lists+linux-acpi@lfdr.de>; Mon, 18 Dec 2023 02:15:58 +0000 (UTC)
Received: from localhost.localdomain (localhost.localdomain [127.0.0.1])
	by smtp.subspace.kernel.org (Postfix) with ESMTP id 5126B2119;
	Mon, 18 Dec 2023 02:15:55 +0000 (UTC)
X-Original-To: linux-acpi@vger.kernel.org
Received: from szxga02-in.huawei.com (szxga02-in.huawei.com [45.249.212.188])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 9825B23A2;
	Mon, 18 Dec 2023 02:15:51 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=quarantine dis=none) header.from=huawei.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=huawei.com
Received: from mail.maildlp.com (unknown [172.19.163.48])
	by szxga02-in.huawei.com (SkyGuard) with ESMTP id 4Stk1p74YbzWjv1;
	Mon, 18 Dec 2023 10:15:26 +0800 (CST)
Received: from kwepemm000004.china.huawei.com (unknown [7.193.23.18])
	by mail.maildlp.com (Postfix) with ESMTPS id 179AA1800BC;
	Mon, 18 Dec 2023 10:15:43 +0800 (CST)
Received: from [10.67.121.59] (10.67.121.59) by kwepemm000004.china.huawei.com
 (7.193.23.18) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256) id 15.1.2507.35; Mon, 18 Dec
 2023 10:15:42 +0800
Message-ID: <26ba9fa9-7871-27c3-0de5-62f61071dacd@huawei.com>
Date: Mon, 18 Dec 2023 10:15:41 +0800
Precedence: bulk
X-Mailing-List: linux-acpi@vger.kernel.org
List-Id: <linux-acpi.vger.kernel.org>
List-Subscribe: <mailto:linux-acpi+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-acpi+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101
 Thunderbird/91.2.0
Subject: Re: [PATCH] cpufreq: CPPC: Resolve the large frequency discrepancy
 from cpuinfo_cur_freq
From: "lihuisong (C)" <lihuisong@huawei.com>
To: "Rafael J. Wysocki" <rafael@kernel.org>
CC: <linux-kernel@vger.kernel.org>, <linux-pm@vger.kernel.org>,
	<linux-arm-kernel@lists.infradead.org>, "linux-acpi@vger.kernel.org"
	<linux-acpi@vger.kernel.org>, <beata.michalska@arm.com>, <sumitg@nvidia.com>,
	<ionela.voinescu@arm.com>, <zengheng4@huawei.com>,
	<yang@os.amperecomputing.com>, <will@kernel.org>, <sudeep.holla@arm.com>,
	<liuyonglong@huawei.com>, <zhanjie9@hisilicon.com>
References: <20231212072617.14756-1-lihuisong@huawei.com>
 <CAJZ5v0jwW0=8cNvC-Vu_o+pEHFpN9nrPD4LXCpmSTgQBTHODgg@mail.gmail.com>
 <486f8563-42b7-a049-97a2-bc0b553926aa@huawei.com>
In-Reply-To: <486f8563-42b7-a049-97a2-bc0b553926aa@huawei.com>
Content-Type: text/plain; charset="UTF-8"; format=flowed
Content-Transfer-Encoding: 8bit
X-ClientProxiedBy: dggems705-chm.china.huawei.com (10.3.19.182) To
 kwepemm000004.china.huawei.com (7.193.23.18)


åœ¨ 2023/12/15 10:41, lihuisong (C) å†™é“:
> Hi Rafael,
>
> Thanks for your review.ðŸ˜
>
> åœ¨ 2023/12/15 3:31, Rafael J. Wysocki å†™é“:
>> On Tue, Dec 12, 2023 at 8:26â€¯AM Huisong Li <lihuisong@huawei.com> wrote:
>>> Many developers found that the cpu current frequency is greater than
>>> the maximum frequency of the platform, please see [1], [2] and [3].
>>>
>>> In the scenarios with high memory access pressure, the patch [1] has
>>> proved the significant latency of cpc_read() which is used to obtain
>>> delivered and reference performance counter cause an absurd frequency.
>>> The sampling interval for this counters is very critical and is 
>>> expected
>>> to be equal. However, the different latency of cpc_read() has a direct
>>> impact on their sampling interval.
>>>
>>> This patch adds a interface, cpc_read_arch_counters_on_cpu, to read
>>> delivered and reference performance counter together. According to my
>>> test[4], the discrepancy of cpu current frequency in the scenarios with
>>> high memory access pressure is lower than 0.2% by stress-ng 
>>> application.
>>>
>>> [1] 
>>> https://lore.kernel.org/all/20231025093847.3740104-4-zengheng4@huawei.com/
>>> [2] 
>>> https://lore.kernel.org/all/20230328193846.8757-1-yang@os.amperecomputing.com/
>>> [3] 
>>> https://lore.kernel.org/all/20230418113459.12860-7-sumitg@nvidia.com/
>>>
>>> [4] My local test:
>>> The testing platform enable SMT and include 128 logical CPU in total,
>>> and CPU base frequency is 2.7GHz. Reading "cpuinfo_cur_freq" for each
>>> physical core on platform during the high memory access pressure from
>>> stress-ng, and the output is as follows:
>>> Â Â  0: 2699133Â Â Â Â  2: 2699942Â Â Â Â  4: 2698189Â Â Â Â  6: 2704347
>>> Â Â  8: 2704009Â Â Â  10: 2696277Â Â Â  12: 2702016Â Â Â  14: 2701388
>>> Â  16: 2700358Â Â Â  18: 2696741Â Â Â  20: 2700091Â Â Â  22: 2700122
>>> Â  24: 2701713Â Â Â  26: 2702025Â Â Â  28: 2699816Â Â Â  30: 2700121
>>> Â  32: 2700000Â Â Â  34: 2699788Â Â Â  36: 2698884Â Â Â  38: 2699109
>>> Â  40: 2704494Â Â Â  42: 2698350Â Â Â  44: 2699997Â Â Â  46: 2701023
>>> Â  48: 2703448Â Â Â  50: 2699501Â Â Â  52: 2700000Â Â Â  54: 2699999
>>> Â  56: 2702645Â Â Â  58: 2696923Â Â Â  60: 2697718Â Â Â  62: 2700547
>>> Â  64: 2700313Â Â Â  66: 2700000Â Â Â  68: 2699904Â Â Â  70: 2699259
>>> Â  72: 2699511Â Â Â  74: 2700644Â Â Â  76: 2702201Â Â Â  78: 2700000
>>> Â  80: 2700776Â Â Â  82: 2700364Â Â Â  84: 2702674Â Â Â  86: 2700255
>>> Â  88: 2699886Â Â Â  90: 2700359Â Â Â  92: 2699662Â Â Â  94: 2696188
>>> Â  96: 2705454Â Â Â  98: 2699260Â Â  100: 2701097Â Â  102: 2699630
>>> 104: 2700463Â Â  106: 2698408Â Â  108: 2697766Â Â  110: 2701181
>>> 112: 2699166Â Â  114: 2701804Â Â  116: 2701907Â Â  118: 2701973
>>> 120: 2699584Â Â  122: 2700474Â Â  124: 2700768Â Â  126: 2701963
>>>
>>> Signed-off-by: Huisong Li <lihuisong@huawei.com>
>> First off, please Cc ACPI-related patches to linux-acpi.
>
> got it.
>
> +linux-acpi@vger.kernel.org
>
>>
>>> ---
>>> Â  arch/arm64/kernel/topology.c | 43 
>>> ++++++++++++++++++++++++++++++++++--
>>> Â  drivers/acpi/cppc_acpi.cÂ Â Â Â  | 22 +++++++++++++++---
>>> Â  include/acpi/cppc_acpi.hÂ Â Â Â  |Â  5 +++++
>>> Â  3 files changed, 65 insertions(+), 5 deletions(-)
>>>
>>> diff --git a/arch/arm64/kernel/topology.c 
>>> b/arch/arm64/kernel/topology.c
>>> index 7d37e458e2f5..c3122154d738 100644
>>> --- a/arch/arm64/kernel/topology.c
>>> +++ b/arch/arm64/kernel/topology.c
>>> @@ -299,6 +299,11 @@ core_initcall(init_amu_fie);
>>> Â  #ifdef CONFIG_ACPI_CPPC_LIB
>>> Â  #include <acpi/cppc_acpi.h>
>>>
>>> +struct amu_counters {
>>> +Â Â Â Â Â Â  u64 corecnt;
>>> +Â Â Â Â Â Â  u64 constcnt;
>>> +};
>>> +
>>> Â  static void cpu_read_corecnt(void *val)
>>> Â  {
>>> Â Â Â Â Â Â Â Â  /*
>>> @@ -322,8 +327,27 @@ static void cpu_read_constcnt(void *val)
>>> Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  0UL : read_constcnt();
>>> Â  }
>>>
>>> +static void cpu_read_amu_counters(void *data)
>>> +{
>>> +Â Â Â Â Â Â  struct amu_counters *cnt = (struct amu_counters *)data;
>>> +
>>> +Â Â Â Â Â Â  /*
>>> +Â Â Â Â Â Â Â  * The running time of the this_cpu_has_cap() might have a 
>>> couple of
>>> +Â Â Â Â Â Â Â  * microseconds and is significantly increased to tens of 
>>> microseconds.
>>> +Â Â Â Â Â Â Â  * But AMU core and constant counter need to be read togeter 
>>> without any
>>> +Â Â Â Â Â Â Â  * time interval to reduce the calculation discrepancy using 
>>> this counters.
>>> +Â Â Â Â Â Â Â  */
>>> +Â Â Â Â Â Â  if (this_cpu_has_cap(ARM64_WORKAROUND_2457168)) {
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â  cnt->corecnt = read_corecnt();
>> This statement is present in both branches, so can it be moved before 
>> the if ()?
> Yes.
> Do you mean adding a blank line before if()?
Sorry, I misunderstood you.
The statement "cnt->corecnt = read_corecnt();" cannot be moved before 
the if().
The AMU core and constant counter need to be read togeter without any 
time interval as described in code comments.
The this_cpu_has_cap() is time-consuming.
That is why I don't use the cpu_read_constcnt() to read constant counter.
>>
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â  cnt->constcnt = 0;
>>> +Â Â Â Â Â Â  } else {
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â  cnt->corecnt = read_corecnt();
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â  cnt->constcnt = read_constcnt();
>>> +Â Â Â Â Â Â  }
>>> +}
>>> +
>>> Â  static inline
>>> -int counters_read_on_cpu(int cpu, smp_call_func_t func, u64 *val)
>>> +int counters_read_on_cpu(int cpu, smp_call_func_t func, void *data)
>>> Â  {
>>> Â Â Â Â Â Â Â Â  /*
>>> Â Â Â Â Â Â Â Â Â  * Abort call on counterless CPU or when interrupts are
>>> @@ -335,7 +359,7 @@ int counters_read_on_cpu(int cpu, 
>>> smp_call_func_t func, u64 *val)
>>> Â Â Â Â Â Â Â Â  if (WARN_ON_ONCE(irqs_disabled()))
>>> Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  return -EPERM;
>>>
>>> -Â Â Â Â Â Â  smp_call_function_single(cpu, func, val, 1);
>>> +Â Â Â Â Â Â  smp_call_function_single(cpu, func, data, 1);
>>>
>>> Â Â Â Â Â Â Â Â  return 0;
>>> Â  }
>>> @@ -364,6 +388,21 @@ bool cpc_ffh_supported(void)
>>> Â Â Â Â Â Â Â Â  return true;
>>> Â  }
>>>
>>> +int cpc_read_arch_counters_on_cpu(int cpu, u64 *delivered, u64 
>>> *reference)
>>> +{
>>> +Â Â Â Â Â Â  struct amu_counters cnts = {0};
>>> +Â Â Â Â Â Â  int ret;
>>> +
>>> +Â Â Â Â Â Â  ret = counters_read_on_cpu(cpu, cpu_read_amu_counters, &cnts);
>>> +Â Â Â Â Â Â  if (ret)
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â  return ret;
>>> +
>>> +Â Â Â Â Â Â  *delivered = cnts.corecnt;
>>> +Â Â Â Â Â Â  *reference = cnts.constcnt;
>>> +
>>> +Â Â Â Â Â Â  return 0;
>>> +}
>>> +
>>> Â  int cpc_read_ffh(int cpu, struct cpc_reg *reg, u64 *val)
>>> Â  {
>>> Â Â Â Â Â Â Â Â  int ret = -EOPNOTSUPP;
>>> diff --git a/drivers/acpi/cppc_acpi.c b/drivers/acpi/cppc_acpi.c
>>> index 7ff269a78c20..f303fabd7cfe 100644
>>> --- a/drivers/acpi/cppc_acpi.c
>>> +++ b/drivers/acpi/cppc_acpi.c
>>> @@ -1299,6 +1299,11 @@ bool cppc_perf_ctrs_in_pcc(void)
>>> Â  }
>>> Â  EXPORT_SYMBOL_GPL(cppc_perf_ctrs_in_pcc);
>>>
>>> +int __weak cpc_read_arch_counters_on_cpu(int cpu, u64 *delivered, 
>>> u64 *reference)
>>> +{
>>> +Â Â Â Â Â Â  return 0;
>>> +}
>>> +
>>> Â  /**
>>> Â Â  * cppc_get_perf_ctrs - Read a CPU's performance feedback counters.
>>> Â Â  * @cpunum: CPU from which to read counters.
>>> @@ -1313,7 +1318,8 @@ int cppc_get_perf_ctrs(int cpunum, struct 
>>> cppc_perf_fb_ctrs *perf_fb_ctrs)
>>> Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  *ref_perf_reg, *ctr_wrap_reg;
>>> Â Â Â Â Â Â Â Â  int pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpunum);
>>> Â Â Â Â Â Â Â Â  struct cppc_pcc_data *pcc_ss_data = NULL;
>>> -Â Â Â Â Â Â  u64 delivered, reference, ref_perf, ctr_wrap_time;
>>> +Â Â Â Â Â Â  u64 delivered = 0, reference = 0;
>>> +Â Â Â Â Â Â  u64 ref_perf, ctr_wrap_time;
>>> Â Â Â Â Â Â Â Â  int ret = 0, regs_in_pcc = 0;
>>>
>>> Â Â Â Â Â Â Â Â  if (!cpc_desc) {
>>> @@ -1350,8 +1356,18 @@ int cppc_get_perf_ctrs(int cpunum, struct 
>>> cppc_perf_fb_ctrs *perf_fb_ctrs)
>>> Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  }
>>> Â Â Â Â Â Â Â Â  }
>>>
>>> -Â Â Â Â Â Â  cpc_read(cpunum, delivered_reg, &delivered);
>>> -Â Â Â Â Â Â  cpc_read(cpunum, reference_reg, &reference);
>>> +Â Â Â Â Â Â  if (cpc_ffh_supported()) {
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ret = cpc_read_arch_counters_on_cpu(cpunum, 
>>> &delivered, &reference);
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â  if (ret) {
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  pr_debug("read arch counters failed, 
>>> ret=%d.\n", ret);
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ret = 0;
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â  }
>>> +Â Â Â Â Â Â  }
>> The above is surely not applicable to every platform using CPPC.Â  Also
>
> cpc_ffh_supported is aimed to control only the platform supported FFH 
> to enter.
> cpc_read_arch_counters_on_cpu is also needed to implemented by each 
> platform according to their require.
> Here just implement this interface for arm64.
>
>> it looks like in the ARM64_WORKAROUND_2457168 enabled case it is just
>> pointless overhead, because "reference" is always going to be 0 here
>> then.
> Right, it is always going to be 0 here for the 
> ARM64_WORKAROUND_2457168 enabled case .
> But ARM64_WORKAROUND_2457168 is a macro releated to ARM.
> It seems that it is not appropriate for this macro to appear this 
> common place for all platform, right?
>
>>
>> Please clean that up.
>>
>>> +Â Â Â Â Â Â  if (!delivered || !reference) {
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â  cpc_read(cpunum, delivered_reg, &delivered);
>>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â  cpc_read(cpunum, reference_reg, &reference);
>>> +Â Â Â Â Â Â  }
>>> +
>>> Â Â Â Â Â Â Â Â  cpc_read(cpunum, ref_perf_reg, &ref_perf);
>>>
>>> Â Â Â Â Â Â Â Â  /*
>>> diff --git a/include/acpi/cppc_acpi.h b/include/acpi/cppc_acpi.h
>>> index 6126c977ece0..07d4fd82d499 100644
>>> --- a/include/acpi/cppc_acpi.h
>>> +++ b/include/acpi/cppc_acpi.h
>>> @@ -152,6 +152,7 @@ extern bool cpc_ffh_supported(void);
>>> Â  extern bool cpc_supported_by_cpu(void);
>>> Â  extern int cpc_read_ffh(int cpunum, struct cpc_reg *reg, u64 *val);
>>> Â  extern int cpc_write_ffh(int cpunum, struct cpc_reg *reg, u64 val);
>>> +extern int cpc_read_arch_counters_on_cpu(int cpu, u64 *delivered, 
>>> u64 *reference);
>>> Â  extern int cppc_get_epp_perf(int cpunum, u64 *epp_perf);
>>> Â  extern int cppc_set_epp_perf(int cpu, struct cppc_perf_ctrls 
>>> *perf_ctrls, bool enable);
>>> Â  extern int cppc_get_auto_sel_caps(int cpunum, struct 
>>> cppc_perf_caps *perf_caps);
>>> @@ -209,6 +210,10 @@ static inline int cpc_write_ffh(int cpunum, 
>>> struct cpc_reg *reg, u64 val)
>>> Â  {
>>> Â Â Â Â Â Â Â Â  return -ENOTSUPP;
>>> Â  }
>>> +static inline int cpc_read_arch_counters_on_cpu(int cpu, u64 
>>> *delivered, u64 *reference)
>>> +{
>>> +Â Â Â Â Â Â  return -EOPNOTSUPP;
>>> +}
>>> Â  static inline int cppc_set_epp_perf(int cpu, struct 
>>> cppc_perf_ctrls *perf_ctrls, bool enable)
>>> Â  {
>>> Â Â Â Â Â Â Â Â  return -ENOTSUPP;
>>> -- 
>> .
>
> _______________________________________________
> linux-arm-kernel mailing list
> linux-arm-kernel@lists.infradead.org
> http://lists.infradead.org/mailman/listinfo/linux-arm-kernel

